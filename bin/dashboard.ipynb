{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DASHBOARD\n",
    "__This notebook is meant setup a training session and evaluate its performances__\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session, get_session\n",
    "import keras.losses as klosses\n",
    "import keras.optimizers as koptimizers\n",
    "import keras.callbacks as kcallbacks\n",
    "import keras.initializers as initializers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load and setup local dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dieze/Documents/OMA/TheraPanacea/thera_reg_oma/utils/LungsLoader.py:32: UserWarning: Subset folder 0 not found in data.\n",
      "  warnings.warn(f\"Subset folder {subset_f[-1:]} not found in data.\")\n",
      "/Users/dieze/Documents/OMA/TheraPanacea/thera_reg_oma/utils/LungsLoader.py:32: UserWarning: Subset folder 1 not found in data.\n",
      "  warnings.warn(f\"Subset folder {subset_f[-1:]} not found in data.\")\n",
      "/Users/dieze/Documents/OMA/TheraPanacea/thera_reg_oma/utils/LungsLoader.py:32: UserWarning: Subset folder 2 not found in data.\n",
      "  warnings.warn(f\"Subset folder {subset_f[-1:]} not found in data.\")\n",
      "/Users/dieze/Documents/OMA/TheraPanacea/thera_reg_oma/utils/LungsLoader.py:32: UserWarning: Subset folder 3 not found in data.\n",
      "  warnings.warn(f\"Subset folder {subset_f[-1:]} not found in data.\")\n",
      "/Users/dieze/Documents/OMA/TheraPanacea/thera_reg_oma/utils/LungsLoader.py:32: UserWarning: Subset folder 4 not found in data.\n",
      "  warnings.warn(f\"Subset folder {subset_f[-1:]} not found in data.\")\n",
      "/Users/dieze/Documents/OMA/TheraPanacea/thera_reg_oma/utils/LungsLoader.py:32: UserWarning: Subset folder 5 not found in data.\n",
      "  warnings.warn(f\"Subset folder {subset_f[-1:]} not found in data.\")\n",
      "/Users/dieze/Documents/OMA/TheraPanacea/thera_reg_oma/utils/LungsLoader.py:32: UserWarning: Subset folder 6 not found in data.\n",
      "  warnings.warn(f\"Subset folder {subset_f[-1:]} not found in data.\")\n",
      "/Users/dieze/Documents/OMA/TheraPanacea/thera_reg_oma/utils/LungsLoader.py:32: UserWarning: Subset folder 7 not found in data.\n",
      "  warnings.warn(f\"Subset folder {subset_f[-1:]} not found in data.\")\n",
      "/Users/dieze/Documents/OMA/TheraPanacea/thera_reg_oma/utils/LungsLoader.py:32: UserWarning: Subset folder 9 not found in data.\n",
      "  warnings.warn(f\"Subset folder {subset_f[-1:]} not found in data.\")\n"
     ]
    }
   ],
   "source": [
    "cur_dir = os.getcwd()\n",
    "base_dir = os.path.dirname(cur_dir)\n",
    "\n",
    "import sys\n",
    "sys.path.append(base_dir)\n",
    "from utils.LungsLoader import LungsLoader\n",
    "from utils.ScanHandler import ScanHandler\n",
    "\n",
    "from src.training.config_file import ConfigFile\n",
    "from src.evaluation.luna_testing import LunaTester\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "loader = LungsLoader()\n",
    "handler = ScanHandler(plt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize a session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_name = \"sandbox_session\"\n",
    "config = ConfigFile(session_name)\n",
    "config.setup_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.networks.networks_utils import blocks\n",
    "from src.networks.MariaNet import MariaNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Setting up model hyperparameters :__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (64, 64, 64)\n",
    "\n",
    "conv_block_kwgs = {\n",
    "                    \"activation\": \"LeakyReLU\",\n",
    "                    \"activation_kwargs\":{\n",
    "                        \"alpha\": 0.3\n",
    "                        },\n",
    "                    \"normalize\": True,\n",
    "                    \"conv_kwargs\": {\n",
    "                      \"kernel_size\": 3,\n",
    "                      \"padding\": \"same\",\n",
    "                      \"kernel_initializer\": initializers.RandomNormal(mean=0.0, stddev=1e-5)\n",
    "                      }\n",
    "                    }\n",
    "squeeze_ratio = 16\n",
    "conv_block = blocks.ConvBlock(**conv_block_kwgs)\n",
    "squeeze_block = blocks.SqueezeExciteBlock(ratio=squeeze_ratio)\n",
    "\n",
    "enc_filters = [32, 64, 128, 32, 32]\n",
    "enc_dilation = [(1, 1, 1), (1, 1, 1), (2, 2, 2), (3, 3, 3), (5, 5, 5)]\n",
    "enc_params = [{\"filters\": n_filter, \"dilation_rate\": dil_rate} for (n_filter, dil_rate) in zip(enc_filters, enc_dilation)]\n",
    "\n",
    "dec_filters = [128, 64, 32, 32, 32]\n",
    "dec_params = [{\"filters\": n_filter} for n_filter in dec_filters]\n",
    "\n",
    "def_flow_nf = 3\n",
    "lin_flow_nf = 12\n",
    "\n",
    "marianet = MariaNet(input_shape,\n",
    "                    enc_params,\n",
    "                     dec_params,\n",
    "                     conv_block,\n",
    "                     squeeze_block,\n",
    "                     def_flow_nf,\n",
    "                     lin_flow_nf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Serialize model builder__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "builder_path = os.path.join(config.session_dir, \"builder.pickle\")\n",
    "marianet.serialize(builder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traning parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Input Shape :__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.set_input_shape(input_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Losses :__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def registration_loss(vol1, vol2):\n",
    "    return klosses.mean_squared_error(vol1, vol2) - 1. * metrics.cross_correlation(vol1, vol2)\n",
    "\n",
    "\n",
    "losses = [registration_loss, klosses.mean_absolute_error, klosses.mean_absolute_error]\n",
    "loss_weights = [1., 1e-5, 1e-5]\n",
    "\n",
    "config.set_losses(losses)\n",
    "config.set_loss_weights(loss_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Optimizer :__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = koptimizers.Adam(lr=1e-2, decay=1e-5)\n",
    "config.set_optimizer(optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Callbacks :__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoints_dir = os.path.join(config.session_dir, ConfigFile.checkpoints_dirname)\n",
    "tensorboard_dir = os.path.join(config.session_dir, ConfigFile.tensorboard_dirname)\n",
    "\n",
    "\n",
    "save_callback = kcallbacks.ModelCheckpoint(os.path.join(checkpoints_dir, ConfigFile.checkpoints_format), \n",
    "                                           verbose=1, \n",
    "                                           save_best_only=True)\n",
    "early_stopping = kcallbacks.EarlyStopping(monitor='val_loss',\n",
    "                                          min_delta=1e-3,\n",
    "                                          patience=20,\n",
    "                                          mode='auto')\n",
    "tbCallBack = kcallbacks.TensorBoard(log_dir=tensorboard_dir, \n",
    "                                    histogram_freq=0, \n",
    "                                    write_graph=True, \n",
    "                                    write_images=True)\n",
    "\n",
    "callbacks = [save_callback, early_stopping, tbCallBack]\n",
    "config.set_callbacks(callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Training scope :__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "steps_per_epoch = 50\n",
    "\n",
    "config.set_epochs(epochs)\n",
    "config.set_steps_per_epoch(steps_per_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Serialize session configs__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.serialize()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
